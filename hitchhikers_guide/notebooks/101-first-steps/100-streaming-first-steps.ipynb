{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c40b19c7-0434-41cf-86cd-a153073577f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run first. then have fun.\n",
    "from pyspark.sql.functions import col\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# keep the default compression codec as zstd\n",
    "spark.conf.set(\"spark.sql.parquet.compression.codec\", \"zstd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdf07ce-0b60-438c-99ed-e0bb25f76fc5",
   "metadata": {},
   "source": [
    "# First Steps: Delta Lake Streaming\n",
    "> Note: This notebook relies heavily on the Apache Spark ecosystem. In the future we will have rust driven notebooks under `first steps` as well. \n",
    "\n",
    "We will discover how to easily create a Delta Lake table using the `datasets/ecomm_behavior_data/parquet/[sm|lg]/` data created in the [../notebooks/100-pre-processing/ecomm_csv_to_parquet.ipynb](./notebooks/100-pre-processing/ecomm_csv_to_parquet.ipynb).\n",
    "\n",
    "1. We will use the `parquet` data to convert to a [Delta Lake table](https://docs.delta.io/latest/delta-batch.html#create-a-table).\n",
    "2. We will also look at creating the table using the [DeltaTable](https://docs.delta.io/latest/api/python/index.html) builder methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fe3dc33-f63a-4551-baf6-fcb36aceedd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/spark/work-dir/hitchhikers_guide/datasets/ecomm_behavior_data/parquet/sm/\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = '/opt/spark/work-dir/hitchhikers_guide/datasets/ecomm_behavior_data'\n",
    "# note: if you download the full dataset from https://www.kaggle.com/datasets/mkechinov/ecommerce-behavior-data-from-multi-category-store,\n",
    "# just use the following and comment out the `-sm.csv` datasets.\n",
    "\n",
    "datasets = ['2019-Oct-sm.csv','2019-Nov-sm.csv']\n",
    "\n",
    "source_dir = 'sm' if datasets[1].endswith('-sm.csv') else 'lg'\n",
    "source_parquet_dir = f\"{dataset_dir}/parquet/{source_dir}/\"\n",
    "\n",
    "# view the source parquet path\n",
    "print(source_parquet_dir)\n",
    "\n",
    "# delta sink information\n",
    "delta_path = f\"{dataset_dir}/delta\"\n",
    "dl_unmanaged_table = \"ecomm\"\n",
    "\n",
    "# managed delta table\n",
    "dl_managed_table = \"ecomm_by_day\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25ff8d8-5ea1-42a4-96c9-a47b3cdd8cd3",
   "metadata": {},
   "source": [
    "# Delta Lake Tables\n",
    "We will learn to create an `empty` Delta Lake table next. There are many reasons that you'll want to create empty tables, for one, this allows you to create the `promise` of eventual data, while first getting things like the tables `schema` locked into place. If none of this is making sense yet, then never fear, you'll learn about `schemas` and `tblproperties` next.\n",
    "\n",
    "If you recall, we used a `StructType` to create a schema when we read the `ecomm_behavior_data` in the [100-pre-processing](../100-pre-processing/ecomm_csv_to_parquet.ipynb) notebook. The StructType is to DataFrames, like a structured data is to a Table row, both are strongly typed and provide a bit of peace of mind when working with a dataset. \n",
    "\n",
    "Structured Data is also one of the most important concepts to keep in mind while working with Streaming datasets.\n",
    "\n",
    "## Structured Data as our Data Contract\n",
    "Delta Lake uses a technique called `schema-on-write`. This means that all data being written by the `writer` or `producer` of a dataset must conform to a known `schema` after the initial `write` which in Delta Lake encapsulates a `transaction`. After the **initial write transaction**, which occurs at the time of table **creation**, a schema will exist. The importance of the `schema` is that it is `type-safe`. Type saftey with our data is also of critical importance for streaming, since a change in type, say from `string` to `integer` would break `backwards-compatibility` and `corrupt` our table. We don't want corrupt tables, so using `schema-on-write` and `schema-enforcement`, both tenents of the Delta Lake architecture, we can rest assured that any changes to our `schema` is backwards compatible*.\n",
    "\n",
    "> note and warning: (*) in the case where we must break backwards compatibility, we can, but it comes at the cost of `overwriting` the entire table and `schema`. This pattern is ripe for broken promises in the case where communication of a breaking-change, isn't broadcast to any downstream consumer (someone or some team that is relying on your data for their data product).\n",
    "\n",
    "We will create an Empty Table next that will hold our ecommerce data.\n",
    "\n",
    "## Creating an Unmanaged Delta Lake Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac87b7c1-f803-483a-83a9-e76eca20cb23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "struct<event_time:timestamp,event_type:string,product_id:int,category_id:bigint,category_code:string,brand:string,price:float,user_id:int,user_session:string,event_date:date>\n"
     ]
    }
   ],
   "source": [
    "# steal the schema pattern\n",
    "source_parquet = (spark.read\n",
    " .format(\"parquet\")\n",
    " .load(source_parquet_dir)\n",
    ")\n",
    "\n",
    "source_schema = source_parquet.schema.simpleString()\n",
    "# using the output of the schema from the reference `parquet` table, we can steal enough information to create our empty table\n",
    "print(source_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "831b346e-5f58-438a-9856-a89b0cff94f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hive Session ID = fb06f80d-5aa6-4e87-96e4-a56a62b6c3aa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:45:00.366 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-23 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:00.371 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:769) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:01.432 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-24 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:01.435 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:01.455 [Thread-4] ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler - Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDOFatalInternalException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:671)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "NestedThrowablesStackTrace:\n",
      "java.lang.reflect.InvocationTargetException\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82)\n",
      "\t... 147 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112)\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72)\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213)\n",
      "\t... 149 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n",
      "\t... 1 more\n",
      "Caused by: ERROR XJ041: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 15 more\n",
      "Caused by: ERROR XBM0A: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source)\n",
      "\t... 12 more\n",
      "\n",
      "22:45:04.480 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-25 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:04.486 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:769) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:05.533 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-26 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:05.536 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:05.546 [Thread-4] ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler - Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDOFatalInternalException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:671)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "NestedThrowablesStackTrace:\n",
      "java.lang.reflect.InvocationTargetException\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82)\n",
      "\t... 147 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112)\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72)\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213)\n",
      "\t... 149 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n",
      "\t... 1 more\n",
      "Caused by: ERROR XJ041: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 15 more\n",
      "Caused by: ERROR XBM0A: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source)\n",
      "\t... 12 more\n",
      "\n",
      "22:45:08.594 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-27 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:08.598 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:769) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:09.645 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-28 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:09.648 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:09.660 [Thread-4] ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler - Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDOFatalInternalException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:671)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "NestedThrowablesStackTrace:\n",
      "java.lang.reflect.InvocationTargetException\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82)\n",
      "\t... 147 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112)\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72)\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213)\n",
      "\t... 149 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n",
      "\t... 1 more\n",
      "Caused by: ERROR XJ041: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 15 more\n",
      "Caused by: ERROR XBM0A: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source)\n",
      "\t... 12 more\n",
      "\n",
      "22:45:12.724 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-29 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:12.727 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:769) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:13.773 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-30 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:13.776 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:13.788 [Thread-4] ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler - Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDOFatalInternalException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:671)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "NestedThrowablesStackTrace:\n",
      "java.lang.reflect.InvocationTargetException\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82)\n",
      "\t... 147 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112)\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72)\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213)\n",
      "\t... 149 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n",
      "\t... 1 more\n",
      "Caused by: ERROR XJ041: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 15 more\n",
      "Caused by: ERROR XBM0A: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source)\n",
      "\t... 12 more\n",
      "\n",
      "22:45:16.834 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-31 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:16.854 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:769) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:17.890 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-32 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:17.893 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:17.909 [Thread-4] ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler - Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDOFatalInternalException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:671)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "NestedThrowablesStackTrace:\n",
      "java.lang.reflect.InvocationTargetException\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82)\n",
      "\t... 147 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112)\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72)\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213)\n",
      "\t... 149 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n",
      "\t... 1 more\n",
      "Caused by: ERROR XJ041: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 15 more\n",
      "Caused by: ERROR XBM0A: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source)\n",
      "\t... 12 more\n",
      "\n",
      "22:45:20.972 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-33 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:20.976 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:769) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:22.032 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-34 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:22.043 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:22.050 [Thread-4] ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler - Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDOFatalInternalException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:671)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "NestedThrowablesStackTrace:\n",
      "java.lang.reflect.InvocationTargetException\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82)\n",
      "\t... 147 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112)\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72)\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213)\n",
      "\t... 149 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n",
      "\t... 1 more\n",
      "Caused by: ERROR XJ041: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 15 more\n",
      "Caused by: ERROR XBM0A: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source)\n",
      "\t... 12 more\n",
      "\n",
      "22:45:25.128 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-35 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:25.132 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:769) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:26.187 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-36 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:26.189 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:26.193 [Thread-4] ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler - Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDOFatalInternalException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:671)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "NestedThrowablesStackTrace:\n",
      "java.lang.reflect.InvocationTargetException\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82)\n",
      "\t... 147 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112)\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72)\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213)\n",
      "\t... 149 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n",
      "\t... 1 more\n",
      "Caused by: ERROR XJ041: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 15 more\n",
      "Caused by: ERROR XBM0A: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source)\n",
      "\t... 12 more\n",
      "\n",
      "22:45:29.237 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-37 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:29.239 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:769) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:30.288 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-38 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:30.289 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 140 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:30.295 [Thread-4] ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler - Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDOFatalInternalException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:671)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "NestedThrowablesStackTrace:\n",
      "java.lang.reflect.InvocationTargetException\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82)\n",
      "\t... 147 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112)\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72)\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213)\n",
      "\t... 149 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n",
      "\t... 1 more\n",
      "Caused by: ERROR XJ041: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 15 more\n",
      "Caused by: ERROR XBM0A: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source)\n",
      "\t... 12 more\n",
      "\n",
      "22:45:33.363 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-39 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:33.372 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor161.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:769) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 138 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 138 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 138 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:34.412 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-40 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:34.414 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor161.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 138 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 138 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 138 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:34.435 [Thread-4] ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler - Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDOFatalInternalException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:671)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "NestedThrowablesStackTrace:\n",
      "java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285)\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor161.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82)\n",
      "\t... 144 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112)\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72)\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213)\n",
      "\t... 146 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n",
      "\t... 1 more\n",
      "Caused by: ERROR XJ041: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 15 more\n",
      "Caused by: ERROR XBM0A: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source)\n",
      "\t... 12 more\n",
      "\n",
      "22:45:37.486 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-41 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:37.491 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor161.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:769) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 138 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 138 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 138 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:38.537 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-42 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:38.540 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor161.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 138 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 138 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 138 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:38.559 [Thread-4] ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler - Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDOFatalInternalException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:671)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "NestedThrowablesStackTrace:\n",
      "java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285)\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor161.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82)\n",
      "\t... 144 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112)\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72)\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213)\n",
      "\t... 146 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n",
      "\t... 1 more\n",
      "Caused by: ERROR XJ041: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 15 more\n",
      "Caused by: ERROR XBM0A: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source)\n",
      "\t... 12 more\n",
      "\n",
      "22:45:41.604 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-43 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:41.606 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor161.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:769) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 138 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 138 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 138 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:42.654 [Thread-4] ERROR com.zaxxer.hikari.pool.HikariPool - HikariPool-44 - Exception during pool initialization.\n",
      "java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 15 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\t... 12 more\n",
      "22:45:42.655 [Thread-4] ERROR DataNucleus.Datastore - Exception thrown creating StoreManager. See the nested exception\n",
      "org.datanucleus.exceptions.NucleusException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:214) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor161.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213) ~[datanucleus-api-jdo-4.2.4.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702) ~[javax.jdo-3.2.0-m3.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139) ~[hadoop-client-api-3.3.4.jar:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94) ~[org.apache.hive_hive-exec-3.1.3.jar:3.1.3]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84) ~[org.apache.hive_hive-standalone-metastore-3.1.3.jar:3.1.3]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119) ~[hive-metastore-2.3.9.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651) ~[hive-exec-2.3.9-core.jar:2.3.9]\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69) ~[spark-hive_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59) ~[io.delta_delta-spark_2.12-3.0.0.jar:3.0.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638) ~[spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659) [spark-sql_2.12-3.5.0.jar:3.5.0]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 138 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 138 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72) ~[HikariCP-2.5.1.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82) ~[datanucleus-rdbms-4.1.19.jar:?]\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source) ~[?:?]\n",
      "\tat jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[?:?]\n",
      "\tat java.lang.reflect.Constructor.newInstance(Unknown Source) ~[?:?]\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203) ~[datanucleus-core-4.1.17.jar:?]\n",
      "\t... 138 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.security.AccessController.doPrivileged(Native Method) ~[?:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source) ~[org.apache.derby_derby-10.14.1.0.jar:?]\n",
      "\tat java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]\n",
      "\t... 1 more\n",
      "22:45:42.660 [Thread-4] ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler - HMSHandler Fatal error: javax.jdo.JDOFatalInternalException: Error creating transactional connection factory\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:671)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "NestedThrowablesStackTrace:\n",
      "java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285)\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor161.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82)\n",
      "\t... 144 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112)\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72)\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213)\n",
      "\t... 146 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n",
      "\t... 1 more\n",
      "Caused by: ERROR XJ041: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 15 more\n",
      "Caused by: ERROR XBM0A: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source)\n",
      "\t... 12 more\n",
      "\n",
      "22:45:42.663 [Thread-4] ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler - HMSHandler Fatal error: MetaException(message:Error creating transactional connection factory)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:208)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n",
      "\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n",
      "\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n",
      "\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n",
      "\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n",
      "\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "Caused by: javax.jdo.JDOFatalInternalException: Error creating transactional connection factory\n",
      "NestedThrowables:\n",
      "java.lang.reflect.InvocationTargetException\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:671)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n",
      "\t... 98 more\n",
      "Caused by: java.lang.reflect.InvocationTargetException\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203)\n",
      "\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285)\n",
      "\tat jdk.internal.reflect.GeneratedConstructorAccessor161.newInstance(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\t... 128 more\n",
      "Caused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82)\n",
      "\t... 144 more\n",
      "Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536)\n",
      "\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112)\n",
      "\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72)\n",
      "\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213)\n",
      "\t... 146 more\n",
      "Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n",
      "\t... 1 more\n",
      "Caused by: ERROR XJ041: Failed to create database 'metastore_db', see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 15 more\n",
      "Caused by: ERROR XBM0A: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source)\n",
      "\t... 12 more\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o99.toString. Trace:\njava.lang.IllegalArgumentException: object is not an instance of declaring class\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Unknown Source)\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o38.sql.\n: org.apache.spark.sql.AnalysisException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:108)\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)\n\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:54)\n\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$1(HiveSessionStateBuilder.scala:69)\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:122)\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:122)\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:319)\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:249)\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableRawMetadata(SessionCatalog.scala:540)\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.getTableMetadata(SessionCatalog.scala:526)\n\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.loadTable(V2SessionCatalog.scala:75)\n\tat org.apache.spark.sql.connector.catalog.TableCatalog.tableExists(TableCatalog.java:164)\n\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.tableExists(V2SessionCatalog.scala:44)\n\tat org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension.tableExists(DelegatingCatalogExtension.java:93)\n\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.org$apache$spark$sql$delta$catalog$SupportsPathIdentifier$$super$tableExists(DeltaCatalog.scala:59)\n\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.$anonfun$tableExists$1(DeltaCatalog.scala:798)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.recordFrameProfile(DeltaCatalog.scala:59)\n\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists(DeltaCatalog.scala:791)\n\tat org.apache.spark.sql.delta.catalog.SupportsPathIdentifier.tableExists$(DeltaCatalog.scala:789)\n\tat org.apache.spark.sql.delta.catalog.DeltaCatalog.tableExists(DeltaCatalog.scala:59)\n\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:42)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Unknown Source)\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1666)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1651)\n\tat org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:406)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:406)\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n\t... 68 more\nCaused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient\n\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:86)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:95)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:148)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:119)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4306)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4374)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4354)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1662)\n\t... 80 more\nCaused by: java.lang.reflect.InvocationTargetException\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n\tat org.apache.hadoop.hive.metastore.utils.JavaUtils.newInstance(JavaUtils.java:84)\n\t... 87 more\nCaused by: MetaException(message:Error creating transactional connection factory)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:84)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8678)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:169)\n\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:94)\n\t... 92 more\nCaused by: MetaException(message:Error creating transactional connection factory)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:208)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80)\n\t... 96 more\nCaused by: javax.jdo.JDOFatalInternalException: Error creating transactional connection factory\nNestedThrowables:\njava.lang.reflect.InvocationTargetException\n\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:671)\n\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:651)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:694)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:484)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:421)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:376)\n\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)\n\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)\n\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59)\n\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:720)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:698)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:692)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:775)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:540)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)\n\t... 98 more\nCaused by: java.lang.reflect.InvocationTargetException\n\tat jdk.internal.reflect.GeneratedConstructorAccessor162.newInstance(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:330)\n\tat org.datanucleus.store.AbstractStoreManager.registerConnectionFactory(AbstractStoreManager.java:203)\n\tat org.datanucleus.store.AbstractStoreManager.<init>(AbstractStoreManager.java:162)\n\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:285)\n\tat jdk.internal.reflect.GeneratedConstructorAccessor161.newInstance(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)\n\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n\t... 128 more\nCaused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"HikariCP\" plugin to create a ConnectionPool gave an error : Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:232)\n\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.initialiseDataSources(ConnectionFactoryImpl.java:117)\n\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.<init>(ConnectionFactoryImpl.java:82)\n\t... 144 more\nCaused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Failed to create database 'metastore_db', see the next exception for details.\n\tat com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:544)\n\tat com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:536)\n\tat com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:112)\n\tat com.zaxxer.hikari.HikariDataSource.<init>(HikariDataSource.java:72)\n\tat org.datanucleus.store.rdbms.connectionpool.HikariCPConnectionPoolFactory.createConnectionPool(HikariCPConnectionPoolFactory.java:176)\n\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:213)\n\t... 146 more\nCaused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.\n\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver$LoginCallable.call(Unknown Source)\n\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n\t... 1 more\nCaused by: ERROR XJ041: Failed to create database 'metastore_db', see the next exception for details.\n\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n\t... 15 more\nCaused by: ERROR XBM0A: The database directory '/opt/spark/work-dir/hitchhikers_guide/notebooks/101-first-steps/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.\n\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)\n\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source)\n\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source)\n\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source)\n\t... 12 more\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Delta Lake Table Location on the File System\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# > note: Delta Lake tables come in two variants (unmanaged and managed)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m    CREATE TABLE IF NOT EXISTS \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdl_unmanaged_table\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m (\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m        event_time TIMESTAMP,\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m        event_type STRING,\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43m        product_id INTEGER,\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;43m        category_id BIGINT,\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43m        category_code STRING,\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;43m        brand STRING,\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;43m        price FLOAT,\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;43m        user_id INTEGER,\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;43m        user_session STRING,\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;43m        event_date DATE\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;43m    ) USING DELTA\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;43m    LOCATION \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdelta_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdl_unmanaged_table\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;43m    PARTITIONED BY (event_date)\u001b[39;49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;43m    TBLPROPERTIES(\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdelta.logRetentionDuration\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minterval 28 days\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m);\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;43m   \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[1;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[1;32m   1630\u001b[0m         )\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:181\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 181\u001b[0m     converted \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_exception\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/spark-3a80a2e1-5f4e-4146-95b3-7cd73f13fbdc/userFiles-cc8faf57-3247-42eb-a257-111283068d67/io.delta_delta-spark_2.12-3.0.0.jar/delta/exceptions.py:160\u001b[0m, in \u001b[0;36m_patch_convert_exception.<locals>.convert_delta_exception\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delta_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m delta_exception\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal_convert_sql_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:133\u001b[0m, in \u001b[0;36mconvert_exception\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Order matters. ParseException inherits AnalysisException.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_instance_of(gw, e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.apache.spark.sql.AnalysisException\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAnalysisException\u001b[49m\u001b[43m(\u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_instance_of(gw, e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.apache.spark.sql.streaming.StreamingQueryException\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StreamingQueryException(origin\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:67\u001b[0m, in \u001b[0;36mCapturedException.__init__\u001b[0;34m(self, desc, stackTrace, cause, origin)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;241m=\u001b[39m convert_exception(cause) \u001b[38;5;28;01mif\u001b[39;00m cause \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m origin\u001b[38;5;241m.\u001b[39mgetCause() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetCause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_origin \u001b[38;5;241m=\u001b[39m origin\n",
      "File \u001b[0;32m/tmp/spark-3a80a2e1-5f4e-4146-95b3-7cd73f13fbdc/userFiles-cc8faf57-3247-42eb-a257-111283068d67/io.delta_delta-spark_2.12-3.0.0.jar/delta/exceptions.py:160\u001b[0m, in \u001b[0;36m_patch_convert_exception.<locals>.convert_delta_exception\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delta_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m delta_exception\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal_convert_sql_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:173\u001b[0m, in \u001b[0;36mconvert_exception\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m    167\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  An exception was thrown from the Python worker. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see the stack trace below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m c\u001b[38;5;241m.\u001b[39mgetMessage()\n\u001b[1;32m    170\u001b[0m     )\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PythonException(msg, stacktrace)\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mUnknownException\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstackTrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstacktrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:65\u001b[0m, in \u001b[0;36mCapturedException.__init__\u001b[0;34m(self, desc, stackTrace, cause, origin)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstackTrace \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     61\u001b[0m     stackTrace\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stackTrace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (SparkContext\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39morg\u001b[38;5;241m.\u001b[39mapache\u001b[38;5;241m.\u001b[39mspark\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mUtils\u001b[38;5;241m.\u001b[39mexceptionString(origin))\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m cause \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m origin\u001b[38;5;241m.\u001b[39mgetCause() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;241m=\u001b[39m convert_exception(origin\u001b[38;5;241m.\u001b[39mgetCause())\n",
      "File \u001b[0;32m/tmp/spark-3a80a2e1-5f4e-4146-95b3-7cd73f13fbdc/userFiles-cc8faf57-3247-42eb-a257-111283068d67/io.delta_delta-spark_2.12-3.0.0.jar/delta/exceptions.py:160\u001b[0m, in \u001b[0;36m_patch_convert_exception.<locals>.convert_delta_exception\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delta_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m delta_exception\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal_convert_sql_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:173\u001b[0m, in \u001b[0;36mconvert_exception\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m    167\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  An exception was thrown from the Python worker. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see the stack trace below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m c\u001b[38;5;241m.\u001b[39mgetMessage()\n\u001b[1;32m    170\u001b[0m     )\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PythonException(msg, stacktrace)\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mUnknownException\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstackTrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstacktrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:65\u001b[0m, in \u001b[0;36mCapturedException.__init__\u001b[0;34m(self, desc, stackTrace, cause, origin)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstackTrace \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     61\u001b[0m     stackTrace\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stackTrace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (SparkContext\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39morg\u001b[38;5;241m.\u001b[39mapache\u001b[38;5;241m.\u001b[39mspark\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mUtils\u001b[38;5;241m.\u001b[39mexceptionString(origin))\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m cause \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m origin\u001b[38;5;241m.\u001b[39mgetCause() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;241m=\u001b[39m convert_exception(origin\u001b[38;5;241m.\u001b[39mgetCause())\n",
      "File \u001b[0;32m/tmp/spark-3a80a2e1-5f4e-4146-95b3-7cd73f13fbdc/userFiles-cc8faf57-3247-42eb-a257-111283068d67/io.delta_delta-spark_2.12-3.0.0.jar/delta/exceptions.py:160\u001b[0m, in \u001b[0;36m_patch_convert_exception.<locals>.convert_delta_exception\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delta_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m delta_exception\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal_convert_sql_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:173\u001b[0m, in \u001b[0;36mconvert_exception\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m    167\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  An exception was thrown from the Python worker. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see the stack trace below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m c\u001b[38;5;241m.\u001b[39mgetMessage()\n\u001b[1;32m    170\u001b[0m     )\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PythonException(msg, stacktrace)\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mUnknownException\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstackTrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstacktrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:65\u001b[0m, in \u001b[0;36mCapturedException.__init__\u001b[0;34m(self, desc, stackTrace, cause, origin)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstackTrace \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     61\u001b[0m     stackTrace\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stackTrace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (SparkContext\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39morg\u001b[38;5;241m.\u001b[39mapache\u001b[38;5;241m.\u001b[39mspark\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mUtils\u001b[38;5;241m.\u001b[39mexceptionString(origin))\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m cause \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m origin\u001b[38;5;241m.\u001b[39mgetCause() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;241m=\u001b[39m convert_exception(origin\u001b[38;5;241m.\u001b[39mgetCause())\n",
      "File \u001b[0;32m/tmp/spark-3a80a2e1-5f4e-4146-95b3-7cd73f13fbdc/userFiles-cc8faf57-3247-42eb-a257-111283068d67/io.delta_delta-spark_2.12-3.0.0.jar/delta/exceptions.py:157\u001b[0m, in \u001b[0;36m_patch_convert_exception.<locals>.convert_delta_exception\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_delta_exception\u001b[39m(e: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJavaObject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CapturedException:\n\u001b[0;32m--> 157\u001b[0m     delta_exception \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_delta_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m delta_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m delta_exception\n",
      "File \u001b[0;32m/tmp/spark-3a80a2e1-5f4e-4146-95b3-7cd73f13fbdc/userFiles-cc8faf57-3247-42eb-a257-111283068d67/io.delta_delta-spark_2.12-3.0.0.jar/delta/exceptions.py:123\u001b[0m, in \u001b[0;36m_convert_delta_exception\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_delta_exception\u001b[39m(e: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJavaObject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[CapturedException]:\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    Convert Delta's Scala concurrent exceptions to the corresponding Python exceptions.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     s: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     c: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJavaObject\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mgetCause()\n\u001b[1;32m    126\u001b[0m     jvm: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJVMView\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_jvm  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:330\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o99.toString. Trace:\njava.lang.IllegalArgumentException: object is not an instance of declaring class\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Unknown Source)\n\n"
     ]
    }
   ],
   "source": [
    "## Delta Lake Table Location on the File System\n",
    "# > note: Delta Lake tables come in two variants (unmanaged and managed)\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {dl_unmanaged_table} (\n",
    "        event_time TIMESTAMP,\n",
    "        event_type STRING,\n",
    "        product_id INTEGER,\n",
    "        category_id BIGINT,\n",
    "        category_code STRING,\n",
    "        brand STRING,\n",
    "        price FLOAT,\n",
    "        user_id INTEGER,\n",
    "        user_session STRING,\n",
    "        event_date DATE\n",
    "    ) USING DELTA\n",
    "    LOCATION '{delta_path}/{dl_unmanaged_table}'\n",
    "    PARTITIONED BY (event_date)\n",
    "    TBLPROPERTIES('delta.logRetentionDuration'='interval 28 days');\n",
    "   \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd9c131-3750-455b-8a90-9d198e9f11cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "The prior `CREATE TABLE` command will generate an empty Delta Lake table. This doesn't mean that the `table` is actually empty though. The table contains `metadata` which provides information such as the table properties, partition columns, and table location information. Given the `source parquet data` is partitioned by `event_date`, we needed to preserve the `daily` partitions in our `parquet` table. This allows us to not think about how we partition as new data is being added to the table. Using the `event_date` table partitions will be written into without our supervision.\n",
    "\n",
    "If you have `tree` installed on your local machine, take a look at the output of calling:\n",
    "\n",
    "`tree ./hitchhikers_guide/datasets/ecomm_behavior_data/delta/`.\n",
    "\n",
    "```\n",
    "./hitchhikers_guide/datasets/ecomm_behavior_data/delta/\n",
    " ecomm\n",
    "     _delta_log\n",
    "         00000000000000000000.json\n",
    "\n",
    "3 directories, 1 file\n",
    "```\n",
    "\n",
    "> Note: If you are using a mac and have brew installed. `brew install tree`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61898a62-0a0d-4f4a-b2e9-de3b93e05a36",
   "metadata": {},
   "source": [
    "## Populate our Empty Table using our Parquet Source Table\n",
    "In order to add records to our newly created `empty` table, we need to just read and write into the new table. \n",
    "\n",
    "> **NOTE**: If you are reading the entire october and november ecomm data you may see a JVM OOM followed by Py4JError: py4j does not exist in the JVM. This means the driver just crashed.\n",
    "\n",
    "> **TIP**: If you are importing the full 2 months of data. Use the isin to import more days at a time.\n",
    "> `.where(col(\"event_date\").isin(\"2019-10-01\",\"2019-10-02\",\"2019-10-03\"))`\n",
    "> This way you can also figure out at what point the data is too big and an inevitable crash will occur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b57c94c-f1ed-4657-aa59-5ce8a31e90cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# providing the source_parquet for completeness. This has been created earlier in the notebook to steal the parquet schema.\n",
    "\n",
    "# if you want to play around with resolving OOM on the big dataset, don't import by day, and watch things fall over. (~14gb into 1gb memory)...\n",
    "#source_parquet = (spark.read\n",
    "# .format(\"parquet\")\n",
    "# .load(f\"{dataset_dir}/parquet/{source_dir}/\")\n",
    "#)\n",
    "\n",
    "source_parquet = (spark.read\n",
    "  .format(\"parquet\")\n",
    "  .load(source_parquet_dir)\n",
    "  .where(col(\"event_date\").eqNullSafe(\"2019-10-01\"))\n",
    "  # .where(col(\"event_date\").isin(\"2019-11-29\",\"2019-11-30\"))\n",
    ")\n",
    "\n",
    "# TIP: sometimes you just want to make sure the data exists\n",
    "# if you view what you are going to write, then you can see if the upstream is empty\n",
    "# with a quick visual (when you are in notebooks), when you are running outside of notebooks\n",
    "# you'll need to rely on `count()`, or other file listing techniques to see if the data\n",
    "# exists, otherwise, your import job could pass with flying colors - while there is still sadly\n",
    "# no data being moved from a -> b.\n",
    "\n",
    "#source_parquet.show(10)\n",
    "\n",
    "(source_parquet\n",
    " .write\n",
    " .format(\"delta\")\n",
    " .option(\"path\", f\"{delta_path}/{dl_unmanaged_table}\")\n",
    " .mode(\"append\")\n",
    " .save()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3ab7b8-e248-46d7-a878-e1b4fb859f51",
   "metadata": {},
   "source": [
    "1. What have you learned in the process of reading the source parquet into the new Delta Table location?\n",
    "2. What patterns have you picked up here? Did you try playing with different strategies for selecting data using the `.where(col(\"event_date\")....)`? What about using a collection of dates, or matches like `2019-10-1*`? If you are new to using PySpark or Spark in general, take a look at the [pyspark.sql.functions](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html) package to help you on your way.\n",
    "3. If you were using the large datasets, what kinds of issues did you run into? \n",
    "\n",
    "Depending on how many actions you were taking. You probably saw: \n",
    "\n",
    "```\n",
    "[warning][gc,alloc] Executor task launch worker for task 5.0 in stage 603.0 (TID 8573): Retried waiting for GCLocker too often allocating 262144 words\n",
    "23/06/19 21:22:03 WARN TaskMemoryManager: Failed to allocate a page (2097136 bytes), try again\n",
    "```\n",
    "\n",
    "Learning to use Warnings and Exceptions to your advantage can be really helpful to understand what sorts of pressure points exist in your applications. It is also much more fun to break things locally, when we aren't experiencing problems in production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428900e8-ef29-408b-94d7-fbfc6bad63a7",
   "metadata": {},
   "source": [
    "### What Makes up a Delta Lake Table?\n",
    "The Delta Lake table is comprised of the `_delta_log` directory, as well as optional `partition` based directories, or in the case of simple tables, just a collection of `part-{uuid}.c000.{compression}.parquet`, which would populate the `partition based directories` as well.\n",
    "\n",
    "```\n",
    "./hitchhikers_guide/datasets/ecomm_behavior_data/delta/\n",
    " ecomm\n",
    "     _delta_log\n",
    "      00000000000000000000.json\n",
    "      00000000000000000001.json\n",
    "     event_date=2019-10-01\n",
    "         part-00002-abb10ec6-6425-4ef1-91e8-ccb05489fa35.c000.zstd.parquet\n",
    "         part-00004-2eda7d21-dcf8-48b5-8e76-0dc6e71575d2.c000.zstd.parquet\n",
    "```\n",
    "\n",
    "You will notice the `zstd` compression. ZSTD compression is like compression on sterioids. We set this earlier on in the notebook using `spark.conf.set(\"spark.sql.parquet.compression.codec\", \"zstd\")`. \n",
    "\n",
    "For comparison, if you comment out the line in the first cell of the notebook, Spark will use the default `snappy` compression codec. This is still a powerful compression codec, but for a size-on-disk comparision.\n",
    "\n",
    "```\n",
    "ls -lh ./hitchhikers_guide/datasets/ecomm_behavior_data/delta/ecomm/event_date=2019-10-01\n",
    "-rw-r--r--  1 {me}  staff    37M Jun 19 13:57 part-00002-3e39ad07-cc35-4ef1-a0eb-77652c3cbc07.c000.snappy.parquet\n",
    "-rw-r--r--  1 {me}  staff   5.6M Jun 19 13:57 part-00004-fb1843f4-bdb7-4578-b14a-257b2525f6b5.c000.snappy.parquet\n",
    "-rw-r--r--  1 {me}  staff    18M Jun 19 13:59 part-00002-abb10ec6-6425-4ef1-91e8-ccb05489fa35.c000.zstd.parquet\n",
    "-rw-r--r--  1 {me}  staff   3.7M Jun 19 13:59 part-00004-2eda7d21-dcf8-48b5-8e76-0dc6e71575d2.c000.zstd.parquet\n",
    "```\n",
    "\n",
    "> For the exact same data, the zstd compression results in a ~48% reduction in size from (37mb->18mb) and a ~66% reduction in size from 5.6mb->3.7mb. That is over 50% size reduction which is bonkers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7b66cb-d6f8-4990-8a67-62570104810b",
   "metadata": {},
   "source": [
    "## Converting an existing External Delta Lake Table to a Managed Table\n",
    "The Delta Lake table we created uses the `./delta/ecomm/` path on the filesystem. This means we need to understand where in the world a given Table lives, which is not a big problem when there are only a few tables (probably stored somewhere using AWS S3 or Azure Blob Storage, or Google Cloud Storage), but this becomes more problematic as more and more tables become available. At a certain point, it becomes essential to use Managed tables.\n",
    "\n",
    "> Managed Delta Lake tables use the Hive Metastore (or hive compatible metastore) for OSS Delta, and if you're working inside Databricks, you can just use [Unity Catalog](https://www.databricks.com/product/unity-catalog) to mix access, authentication alongside your Table metadata.\n",
    "\n",
    "Given this project is all about using OSS Delta, we're riding the `local` spark-warehouse route, which can be seen under the `spark-warehouse` directory to the left of this notebook (in the filesystem view). You'll also notice there is a `metastore_db`. This directory stores the information commonly stored in the Hive Metastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1315b44-efc1-44a3-bd99-b6ed5d89b2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if you want to check what current databases exist, or what tables exist you can use the following.\n",
    "spark.catalog.listDatabases()\n",
    "spark.catalog.listTables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b654e8-569e-4b55-a9f5-d0cfaf82e31f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the Managed Table Definition\n",
    "# also note - we are keeping the `unmanaged` location in tact and copying files into the new location\n",
    "# The only difference between the external table definition and the managed table definition is the `database.table` vs the `delta.\n",
    "spark.sql(f\"\"\"\n",
    "  CREATE TABLE IF NOT EXISTS default.`{dl_managed_table}` (\n",
    "    event_time TIMESTAMP,\n",
    "    event_type STRING,\n",
    "    product_id INTEGER,\n",
    "    category_id BIGINT,\n",
    "    category_code STRING,\n",
    "    brand STRING,\n",
    "    price FLOAT,\n",
    "    user_id INTEGER,\n",
    "    user_session STRING,\n",
    "    event_date DATE\n",
    "  ) USING DELTA\n",
    "  PARTITIONED BY (event_date)\n",
    "  TBLPROPERTIES(\n",
    "    'delta.logRetentionDuration'='interval 28 days',\n",
    "    'catalog.team_name'='dldg_authors',\n",
    "    'catalog.engineering.comms.slack'='https://delta-users.slack.com/archives/CG9LR6LN4'\n",
    "  );\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8fb30a-9c28-4dcc-ae50-bf38d162f7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add some additional table properties like the table classification (pii? all-access?)\n",
    "spark.sql(f\"\"\"\n",
    "  ALTER TABLE default.`{dl_managed_table}` \n",
    "  SET TBLPROPERTIES (\n",
    "    'catalog.engineering.comms.email'='dldg_authors@gmail.com',\n",
    "    'catalog.table.classification'='all-access'\n",
    "  )\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469a4fb9-1922-4796-9eeb-90b9e0810a09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a little glimpse into the table history (what actions have occured - otherwise known as transactions)\n",
    "(DeltaTable.forName(spark, f\"default.{dl_managed_table}\")\n",
    " .history(10)\n",
    " .select(\"version\", \"timestamp\", \"operation\", \"operationParameters\")\n",
    " .show(10, truncate=True, vertical=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ed6c2-610f-4b74-acb5-12ce2bbca79b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using the createIfNotExists utility\n",
    "# can be used instead of the prior two cells\n",
    "(DeltaTable.createIfNotExists(spark)\n",
    "    .tableName(f\"default.{dl_managed_table}\")\n",
    "    .property(\"description\", \"Retail Ecomm Dataset. This can be used to forecast holiday seasonality for multiple categories\")\n",
    "    .addColumn(\"event_time\", \"TIMESTAMP\")\n",
    "    .addColumn(\"event_type\", \"STRING\")\n",
    "    .addColumn(\"product_id\", \"INTEGER\")\n",
    "    .addColumn(\"category_id\", \"BIGINT\")\n",
    "    .addColumn(\"brand\", \"STRING\")\n",
    "    .addColumn(\"price\", \"FLOAT\")\n",
    "    .addColumn(\"user_id\", \"INTEGER\")\n",
    "    .addColumn(\"user_session\", \"STRING\")\n",
    "    .addColumn(\"event_date\", \"DATE\")\n",
    "    .partitionedBy(\"event_date\")\n",
    "    .property(\"catalog.team_name\", \"dldg_authors\")\n",
    "    .property(\"catalog.engineering.comms.slack\",\n",
    "\t\"https://delta-users.slack.com/archives/CG9LR6LN4\")\n",
    "    .property(\"catalog.engineering.comms.email\",\"dldg_authors@gmail.com\")\n",
    "    .property(\"catalog.table.classification\",\"all-access\")\n",
    "    .execute()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7610ae2-446e-44e8-9432-c2f1af71215a",
   "metadata": {},
   "source": [
    "The only immediate difference between creating a non-managed table and a managed table all comes down to the table location: \n",
    "\n",
    "```\n",
    "delta.`{delta_path}/{dl_unmanaged_table}` vs default.`{dl_managed_table}`\n",
    "```\n",
    "\n",
    "With the managed table, you can also create additional `databases` using the `CREATE DATABASE` syntax. We are currenlty using the `default` database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87401fa5-ed74-43cf-b2ff-f81a47f1d832",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# see the unmanaged Delta Table path\n",
    "print(f\"{delta_path}/{dl_unmanaged_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484f8ab1-b7b9-4d4b-801c-676f4bd8b7bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# look up the unmanaged source table by path\n",
    "#dt = DeltaTable.forPath(spark, f\"{delta_path}/{dl_unmanaged_table}\").detail().show(1, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b9f80-40da-4c33-bf4e-389f7c863657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: the startup.sh adds this information to the session. Having a shared warehouse directory allows us to reuse tables between notebooks\n",
    "spark.conf.get(\"spark.sql.warehouse.dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92651bec-01bb-4cc2-b8fb-52e3de5b0664",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read from the external Delta Lake location\n",
    "# write into the Managed Delta Lake location\n",
    "\n",
    "sourceTable = DeltaTable.forPath(spark, f\"{delta_path}/{dl_unmanaged_table}\")\n",
    "tableDf = sourceTable.toDF()\n",
    "(\n",
    "    tableDf\n",
    "    .where(col(\"event_date\").eqNullSafe(\"2019-10-01\"))\n",
    "    #.where(col(\"event_date\").isin(\"2019-11-28\", \"2019-11-29\", \"2019-11-30\"))\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"append\")\n",
    "    .saveAsTable(f\"default.{dl_managed_table}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa66f71-f36c-4661-a73e-5a5f55418f29",
   "metadata": {},
   "source": [
    "## Inspect the Table\n",
    "> Now that you have data in your unmanaged table. Take a peek. What is interesting to you?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65543fcf-c3e5-413b-937e-cc924db5acb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# peek at table details\n",
    "(DeltaTable.forName(spark, f\"default.{dl_unmanaged_table}\")\n",
    "   .detail()\n",
    "   .show(1, truncate=False, vertical=True)\n",
    ")\n",
    "# view differences in describe extended\n",
    "#spark.sql(\"describe extended default.ecomm_by_day\").show(truncate=True, vertical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca47747f-84bc-46ce-ab23-689ed8aa57e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Looking at just the Table Properties\n",
    "table_info = DeltaTable.forName(spark, \"default.ecomm_by_day\").detail()\n",
    "# view the table properties locally (call first then slice by the properties index)\n",
    "tblproperties = table_info.first()['properties']\n",
    "tblproperties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068932e-9b99-4f85-833c-b864bc0de2cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.table(f\"default.{dl_managed_table}\").show(2, truncate=True, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910ef125-8021-4a75-a968-bbb22a06fc3d",
   "metadata": {},
   "source": [
    "## Converting an existing Parquet Table to Delta Lake\n",
    "Using the `convertToDelta` method via the `DeltaTable` python utility enables us to easily create our Delta Lake table in place. In place just means that the table will not have to be copied and moved, furthermore, since Delta Lake uses Parquet all that is modified is the addition of the `_delta_log` file in the root of the table. \n",
    "\n",
    "> note: if you want to use the convertToDelta utility function, just uncomment the following cell and run it, otherwise, skip on to creating a new Delta Lake table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e419977-aa92-4fd2-af5d-7fcbb326b4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The convertToDelta method will take an existing `Parquet` table, and convert it in place to a DeltaLake table.\n",
    "#parquet_table_dir = f\"{dataset_dir}/parquet/{source_dir}/\"\n",
    "# dt = DeltaTable.convertToDelta(spark, f\"parquet.`{parquet_table_dir}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e27049-8af7-40d6-a062-493b0e7e8d08",
   "metadata": {
    "tags": []
   },
   "source": [
    "# What We Learned\n",
    "1. How to use an existing Parquet Table to create an Unmanaged and Managed Delta Lake Table\n",
    "2. How to View the Table Metadata using the `describe extended table` SQL command and the `DeltaTable.forName...detail()` view.\n",
    "3. How to slice the Table detail and view the `properties`. This allows us to quickly view important metadata about the Delta Lake table and we'll see how to use the Table Properties for more and more in other parts of the Guide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cd4cf6-f535-45b7-b14e-1e410aa8ac87",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What's Next?\n",
    "Now we can use the Managed `ecomm` table as we explore how to use Delta Lake Streaming. \n",
    "\n",
    "1. [Delta Lake Streaming 101](./dl-streaming-101.ipynb) is a gentle introduction to Delta Lake Streaming. This is a necessary part of learning how to effectively use Delta Lake for fun and profit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
