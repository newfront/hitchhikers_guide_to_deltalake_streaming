{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70c7e020-7223-4619-b9da-bce606a5b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.protobuf.functions import from_protobuf\n",
    "from pyspark.sql.types import DateType\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.streaming import StreamingQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6940d260-6a5d-4a27-bef6-ac1cbbc42683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def read_binary_at(path: Path):\n",
    "    with path.open(\"rb\") as fb:\n",
    "        bindata = fb.read()\n",
    "    return bindata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e51d0ef-2409-4343-818e-053fb231f0f9",
   "metadata": {},
   "source": [
    "## Note on Running the Following Examples\n",
    "1. If you have gone through the process of running [highwire](https://github.com/datacircus/highwire) and have populated data using [100_automatic_kafka_to_tin_delta.ipynb](./100_automatic_kafka_to_tin_delta.ipynb), then you will have the table `default.coffeeco_v1_orders_tin`.\n",
    "2. If you haven't run the 100 level notebook, you can change the Delta reference to point to `/opt/spark/work-dir/hitchhikers_guide/datasets/coffeeco_v1_orders_tin` so that you don't need to build and run `highwire`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce535b6e-7d2d-4439-b454-6545d386925e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_path=/opt/spark/work-dir/hitchhikers_guide/applications/ringmaster_tin_to_bronze/v0.0.1/_checkpoints\n"
     ]
    }
   ],
   "source": [
    "app_name = \"ringmaster_tin_to_bronze\"\n",
    "app_version = \"v0.0.1\"\n",
    "\n",
    "delta_source_table = \"default.coffeeco_v1_orders_tin\"\n",
    "\n",
    "protobuf_descriptor_path: Path = (\n",
    "    Path('/opt/spark/work-dir/hitchhikers_guide')\n",
    "    .joinpath(\"common\",\"protobuf\",\"coffeeco_v1\",\"descriptor.bin\")\n",
    "    .absolute()\n",
    ")\n",
    "tin_protobuf_message_name = \"coffeeco.v1.Order\"\n",
    "\n",
    "checkpoint_dir = \"/opt/spark/work-dir/hitchhikers_guide/applications\"\n",
    "checkpoint_path = f\"{checkpoint_dir}/{app_name}/{app_version}/_checkpoints\"\n",
    "print(f\"checkpoint_path={checkpoint_path}\")\n",
    "\n",
    "delta_sink_table = \"default.coffeeco_v1_orders_tin\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04129eca-85b2-4765-8a34-a428f6748781",
   "metadata": {},
   "source": [
    "## We will start simple. We will fetch the Table and Decode in Batch\n",
    "> This allows us to ensure things are wired up correctly, and let's us have fun exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189638a-418d-46da-a82a-c3eea82d597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_source_tin: DeltaTable = DeltaTable.forName(spark, delta_source_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "791b933a-b4bd-408a-86c8-e5e10249efe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+\n",
      "|                 key|               value|           timestamp|      date|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|[53 63 6F 74 74 2...|[0A 0B 08 91 FD 8...|2024-06-07 21:41:...|2024-06-07|\n",
      "|[53 63 6F 74 74 2...|[0A 0C 08 E1 FD 8...|2024-06-07 21:42:...|2024-06-07|\n",
      "|[53 63 6F 74 74 2...|[0A 0C 08 FC FD 8...|2024-06-07 21:43:...|2024-06-07|\n",
      "|[53 63 6F 74 74 2...|[0A 0C 08 C8 84 8...|2024-06-07 21:57:...|2024-06-07|\n",
      "|[53 63 6F 74 74 2...|[0A 0C 08 93 86 8...|2024-06-07 22:00:...|2024-06-07|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_source_tin.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c7c3c-2647-4a5d-8051-0795defe6e26",
   "metadata": {},
   "source": [
    "## Next. We need to load the Binary Protobuf Descriptor and Decode the Protobuf\n",
    "1. Using the `from_protobuf` method and the `binaryDescriptorSet` we will decode the `coffeeco.v1.Order` messages.\n",
    "2. Once we've decoded the `value:bytes` into `order:struct`, we can have fun with the baseline dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d23b8af0-9919-4782-9d9e-90c1350aa121",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffeecov1_bin = read_binary_at(protobuf_descriptor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f344e710-d2a4-49d6-9b3a-342d17bb9c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_orders_df = (\n",
    "    dt_source_tin.toDF()\n",
    "    .select(\n",
    "        \"date\",\n",
    "        \"timestamp\",\n",
    "        from_protobuf(\n",
    "            data=col(\"value\"),\n",
    "            messageName=tin_protobuf_message_name,\n",
    "            options={\"mode\": \"FAILFAST\"},\n",
    "            binaryDescriptorSet=coffeecov1_bin\n",
    "        ).alias(\"order\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8a5b019-fc1b-41f6-a9cf-8190783b7205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- order: struct (nullable = true)\n",
      " |    |-- order_created: timestamp (nullable = true)\n",
      " |    |-- purchased_at: struct (nullable = true)\n",
      " |    |    |-- store_id: string (nullable = true)\n",
      " |    |    |-- created: timestamp (nullable = true)\n",
      " |    |    |-- opened_on: timestamp (nullable = true)\n",
      " |    |    |-- closed_permanently_on: timestamp (nullable = true)\n",
      " |    |    |-- status: string (nullable = true)\n",
      " |    |-- customer: struct (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- uuid: string (nullable = true)\n",
      " |    |    |-- first_seen: timestamp (nullable = true)\n",
      " |    |    |-- customer_type: string (nullable = true)\n",
      " |    |    |-- loyalty_member_id: string (nullable = true)\n",
      " |    |-- items: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = false)\n",
      " |    |    |    |-- coffee: struct (nullable = true)\n",
      " |    |    |    |    |-- coffee: struct (nullable = true)\n",
      " |    |    |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |    |    |-- vendor: string (nullable = true)\n",
      " |    |    |    |    |    |-- roast: string (nullable = true)\n",
      " |    |    |    |    |    |-- flavor_profile: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: string (containsNull = false)\n",
      " |    |    |    |    |-- size: string (nullable = true)\n",
      " |    |    |    |    |-- style: string (nullable = true)\n",
      " |    |-- total: struct (nullable = true)\n",
      " |    |    |-- currency: string (nullable = true)\n",
      " |    |    |-- units: long (nullable = true)\n",
      " |    |    |-- nanos: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coffee_orders_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2211f33d-7c50-423b-823d-d0042a038af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+------------+-----------------------------+\n",
      "|date      |timestamp              |name        |total                        |\n",
      "+----------+-----------------------+------------+-----------------------------+\n",
      "|2024-06-07|2024-06-07 21:41:37.032|Scott Haines|{CURRENCY_CODE_USD, 28, NULL}|\n",
      "|2024-06-07|2024-06-07 21:42:57.921|Scott Haines|{CURRENCY_CODE_USD, 30, 75}  |\n",
      "|2024-06-07|2024-06-07 21:43:24.769|Scott Haines|{CURRENCY_CODE_USD, 12, 50}  |\n",
      "|2024-06-07|2024-06-07 21:57:28.328|Scott Haines|{CURRENCY_CODE_USD, 24, NULL}|\n",
      "|2024-06-07|2024-06-07 22:00:51.321|Scott Haines|{CURRENCY_CODE_USD, 25, NULL}|\n",
      "+----------+-----------------------+------------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(coffee_orders_df.select(\"date\", \"timestamp\", \"order.customer.name\", \"order.total\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c7dedc-1c85-4d41-8191-ff1d459fa769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
