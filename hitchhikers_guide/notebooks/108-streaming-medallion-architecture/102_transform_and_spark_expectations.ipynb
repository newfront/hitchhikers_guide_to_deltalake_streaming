{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca64dfa0-05a2-4b2b-8bc7-352e21a3584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spark-expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ba25cc-09b0-4157-97eb-7fdddccc836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop if rules table exists\n",
    "spark.sql(\"drop table if exists default.coffeeco_tin_dq_rules\")\n",
    "\n",
    "# create rules table \n",
    "spark.sql(\"\"\"create table if not exists default.coffeeco_tin_dq_rules (\n",
    "    product_id STRING,  \n",
    "    table_name STRING,  \n",
    "    rule_type STRING,  \n",
    "    rule STRING,  \n",
    "    column_name STRING,  \n",
    "    expectation STRING,  \n",
    "    action_if_failed STRING,  \n",
    "    tag STRING,  \n",
    "    description STRING,  \n",
    "    enable_for_source_dq_validation BOOLEAN,  \n",
    "    enable_for_target_dq_validation BOOLEAN,  \n",
    "    is_active BOOLEAN,  \n",
    "    enable_error_drop_alert BOOLEAN,  \n",
    "    error_drop_threshold INT,  \n",
    "    query_dq_delimiter STRING,  \n",
    "    enable_querydq_custom_output BOOLEAN\n",
    ")\n",
    "    USING delta\"\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69c56d9-2bd6-4411-b5f3-465557122947",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select * from default.coffeeco_tin_dq_rules\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afbd7f9-4760-423d-b22b-beea0b85852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_yaml=\"\"\"\n",
    "rules:\n",
    "- action_if_failed: fail\n",
    "  column_name: total_nanos\n",
    "  description: total_nanos should not be null\n",
    "  enable_error_drop_alert: false\n",
    "  enable_for_source_dq_validation: false\n",
    "  enable_for_target_dq_validation: false\n",
    "  enable_querydq_custom_output: null\n",
    "  error_drop_threshold: 0\n",
    "  expectation: total_nanos is not null\n",
    "  is_active: true\n",
    "  product_id: coffeeco\n",
    "  query_dq_delimiter: null\n",
    "  rule: total_nanos_is_not_null\n",
    "  rule_type: row_dq\n",
    "  table_name: default.coffeeco_v1_orders_bronze\n",
    "  tag: accuracy\n",
    "- action_if_failed: drop\n",
    "  column_name: store_closed_permanently_on\n",
    "  description: store_closed_permanently_on should be greater than when the order is created, as closed stores cannot have orders\n",
    "  enable_error_drop_alert: false\n",
    "  enable_for_source_dq_validation: true\n",
    "  enable_for_target_dq_validation: true\n",
    "  enable_querydq_custom_output: null\n",
    "  error_drop_threshold: 0\n",
    "  expectation: `store_closed_permanently_on` > `timestamp`\n",
    "  is_active: true\n",
    "  product_id: coffeeco\n",
    "  query_dq_delimiter: null\n",
    "  rule: closed_store_shouldnt_have_orders\n",
    "  rule_type: row_dq\n",
    "  table_name: default.coffeeco_v1_orders_bronze\n",
    "  tag: validity\n",
    "- action_if_failed: ignore\n",
    "  column_name: total_units\n",
    "  description: sum of total units should be greater than 200\n",
    "  enable_error_drop_alert: false\n",
    "  enable_for_source_dq_validation: false\n",
    "  enable_for_target_dq_validation: true\n",
    "  enable_querydq_custom_output: null\n",
    "  error_drop_threshold: 0\n",
    "  expectation: sum(total_units) > 200\n",
    "  is_active: true\n",
    "  product_id: coffeeco\n",
    "  query_dq_delimiter: null\n",
    "  rule: sum_total_units_gt_200\n",
    "  rule_type: agg_dq\n",
    "  table_name: default.coffeeco_v1_orders_bronze\n",
    "  tag: validity\n",
    "- action_if_failed: ignore\n",
    "  column_name: order_created,store_id\n",
    "  description: detect duplicates\n",
    "  enable_error_drop_alert: false\n",
    "  enable_for_source_dq_validation: false\n",
    "  enable_for_target_dq_validation: true\n",
    "  enable_querydq_custom_output: True\n",
    "  error_drop_threshold: 0\n",
    "  expectation: (select count(*) from (select order_created, store_id from coffeeco_bronze_view t1 join default.coffeeco_v1_orders_bronze t2  on t1.order_created=t2.order_created, t1.store_id=t2.store_id)) = 0\n",
    "  is_active: true\n",
    "  product_id: coffeeco\n",
    "  query_dq_delimiter: null\n",
    "  rule: duplication_records_should_not_exist\n",
    "  rule_type: query_dq\n",
    "  table_name: default.coffeeco_v1_orders_bronze\n",
    "  tag: validity\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a8293b-1806-4df7-9e00-f50b3bd09120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Rules\n",
    "import yaml\n",
    "from pyspark.sql.types import StringType, BooleanType, IntegerType, StructType, StructField\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"product_id\", StringType(), nullable=False),\n",
    "    StructField(\"table_name\", StringType(), nullable=False),\n",
    "    StructField(\"rule_type\", StringType(), nullable=False),\n",
    "    StructField(\"rule\", StringType(), nullable=False),\n",
    "    StructField(\"column_name\", StringType(), nullable=False),\n",
    "    StructField(\"expectation\", StringType(), nullable=False),\n",
    "    StructField(\"action_if_failed\", StringType(), nullable=False),\n",
    "    StructField(\"tag\", StringType(), nullable=False),\n",
    "    StructField(\"description\", StringType(), nullable=False),\n",
    "    StructField(\"enable_for_source_dq_validation\", BooleanType(), nullable=False),\n",
    "    StructField(\"enable_for_target_dq_validation\", BooleanType(), nullable=False),\n",
    "    StructField(\"is_active\", BooleanType(), nullable=False),\n",
    "    StructField(\"enable_error_drop_alert\", BooleanType(), nullable=False),\n",
    "    StructField(\"error_drop_threshold\", IntegerType(), nullable=False),\n",
    "    StructField(\"query_dq_delimiter\", StringType(), nullable=True),\n",
    "    StructField(\"enable_querydq_custom_output\", BooleanType(), nullable=True)\n",
    "])\n",
    "\n",
    "rules_data = yaml.safe_load(rules_yaml)\n",
    "rules_df = spark.createDataFrame(rules_data[\"rules\"], schema)\n",
    "rules_df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(f\"{database}.{rule_table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7eb188-d7c2-4e04-8cd1-6ae17dd52270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Tin table as a streaming source\n",
    "coffee_orders_df = spark.readStream.format(\"delta\")\\\n",
    "    .option(\"withEventTimeOrder\", \"true\")\\\n",
    "    .table(\"default.coffeeco_v1_orders_tin\")\\\n",
    "    .withWatermark(\"timestamp\", \"10 seconds\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c0d4b6df-7ad9-4b51-86b1-8a771cc20b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denorm the data in Tin as needed\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "def denorm(df):\n",
    "    denorm_df = coffee_orders_df.select(\n",
    "        \"date\",\n",
    "        \"timestamp\",\n",
    "        col(\"order.order_created\").alias(\"order_created\"),\n",
    "        col(\"order.purchased_at.store_id\").alias(\"store_id\"),\n",
    "        col(\"order.purchased_at.created\").alias(\"store_created\"),\n",
    "        col(\"order.purchased_at.opened_on\").alias(\"store_opened_on\"),\n",
    "        col(\"order.purchased_at.closed_permanently_on\").alias(\"store_closed_permanently_on\"),\n",
    "        col(\"order.purchased_at.status\").alias(\"store_status\"),\n",
    "        col(\"order.customer.name\").alias(\"customer_name\"),\n",
    "        col(\"order.customer.uuid\").alias(\"customer_uuid\"),\n",
    "        col(\"order.customer.first_seen\").alias(\"customer_first_seen\"),\n",
    "        col(\"order.customer.customer_type\").alias(\"customer_type\"),\n",
    "        col(\"order.customer.loyalty_member_id\").alias(\"loyalty_member_id\"),\n",
    "        col(\"order.items\").alias(\"items\"),\n",
    "        col(\"order.total.currency\").alias(\"total_currency\"),\n",
    "        col(\"order.total.units\").alias(\"total_units\"),\n",
    "        col(\"order.total.nanos\").alias(\"total_nanos\")\n",
    "    )\n",
    "    first_row = denorm_df.limit(1)\n",
    "    row_to_copy = row_to_copy.withColumn(\"store_closed_permanently_on\", lit(\"2024-01-01 00:00:00\"))\n",
    "    return denorm_df.union(row_to_copy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268752e8-4e92-4b56-8c83-0e74415841d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each batch run  Spark Expectations before writing into Bronze Layer\n",
    "from datetime import date\n",
    "from spark_expectations.core.expectations import (\n",
    "    SparkExpectations,\n",
    "    WrappedDataFrameWriter,\n",
    ")\n",
    "from spark_expectations.config.user_config import Constants as user_config\n",
    "\n",
    "def write_to_bronze(df, batch_id):\n",
    "    writer = WrappedDataFrameWriter().mode(\"append\").format(\"delta\")\n",
    "    se: SparkExpectations = SparkExpectations(\n",
    "        product_id=\"coffeeco\",\n",
    "        rules_df=spark.table(\"default.coffeeco_tin_dq_rules\"),\n",
    "        stats_table=\"default.coffeeco_dq_stats\",\n",
    "        stats_table_writer=writer,\n",
    "        target_and_error_table_writer=writer,\n",
    "        debugger=False,\n",
    "        # stats_streaming_options={user_config.se_enable_streaming: False},\n",
    "    )\n",
    "    \n",
    "    dic_job_info = {\n",
    "        \"job\": \"coffeeco_load_tin_bronze\",\n",
    "        \"Region\": \"NA\",\n",
    "        \"Snapshot\": date.today(),\n",
    "    }\n",
    "    \n",
    "    user_conf = {\n",
    "        user_config.se_notifications_enable_email: False,\n",
    "        user_config.se_notifications_email_smtp_host: \"mailhost.com\",\n",
    "        user_config.se_notifications_email_smtp_port: 25,\n",
    "        user_config.se_notifications_email_from: \"\",\n",
    "        user_config.se_notifications_email_to_other_mail_id: \"\",\n",
    "        user_config.se_notifications_email_subject: \"spark expectations - data quality - notifications\",\n",
    "        user_config.se_notifications_enable_slack: False,\n",
    "        user_config.se_notifications_slack_webhook_url: \"\",\n",
    "        user_config.se_notifications_on_start: True,\n",
    "        user_config.se_notifications_on_completion: True,\n",
    "        user_config.se_notifications_on_fail: True,\n",
    "        user_config.se_notifications_on_error_drop_exceeds_threshold_breach: True,\n",
    "        user_config.se_notifications_on_error_drop_threshold: 15,\n",
    "        user_config.se_enable_query_dq_detailed_result: True,\n",
    "        user_config.se_enable_agg_dq_detailed_result: True,\n",
    "        # user_config.querydq_output_custom_table_name: \"default.dq_stats_detailed_outputt\",\n",
    "        user_config.se_enable_error_table: True,\n",
    "        user_config.se_dq_rules_params: {\n",
    "            \"env\": \"dev\",\n",
    "            \"table\": \"coffeeco_v1_orders_bronze\",\n",
    "        },\n",
    "        user_config.se_job_metadata: str(dic_job_info),\n",
    "    }\n",
    "\n",
    "    @se.with_expectations(\n",
    "        target_table=\"default.coffeeco_v1_orders_bronze\",\n",
    "        write_to_table=True,\n",
    "        write_to_temp_table=False,\n",
    "        user_conf=user_conf,\n",
    "        target_table_view=\"coffeeco_bronze_view\"\n",
    "    )\n",
    "    def build_bronze(bronze_df):\n",
    "        return bronze_df\n",
    "\n",
    "    build_bronze(denorm(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986c735f-ed1d-4317-aff8-17a93b6a725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to bronze Layer\n",
    "query = coffee_orders_df.writeStream\\\n",
    "    .foreachBatch(write_to_bronze)\\\n",
    "    .queryName(\"WriteToBronzeWithSE\")\\\n",
    "    .option(\"checkpointLocation\", checkpoint_path)\\\n",
    "    # .trigger(processingTime='5 seconds')\\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d743d86-6b19-4ab7-b350-467403405748",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db645b65-4290-4a91-a80e-075605cb134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Bronze Table\n",
    "coffee_v1_bronze_df = spark.sql(\"select * from default.coffeeco_v1_orders_bronze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea95580-1a8b-401c-a92e-f0fa839fd764",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_v1_bronze_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05cf79a-760c-4583-9173-e979d8c052fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the error table from bronze layer which has dropped records from SE\n",
    "coffee_v1_bronze_errors_df = spark.sql(\"select * from default.coffeeco_v1_orders_bronze_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c666bece-6492-4ed1-812c-752ac59c7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_v1_bronze_errors_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da76a008-e226-41f3-ab79-758b727e57bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_v1_bronze_errors_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf39e2c-a752-426b-adae-f9514d72f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the stats table\n",
    "stats_df = spark.sql(\"select * from default.coffeeco_dq_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93fa12c-33ae-4138-8fe0-7f6683d00a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb29685c-eadd-43db-b509-feb764ee84d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a658c8-9043-478a-b798-83280082322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the stats detailed table\n",
    "stats_detailed_df = spark.sql(\"select * from default.coffeeco_dq_stats_detailed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e781460a-9dbe-410d-8305-abaa3f308d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_detailed_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061de6c5-5abb-4a42-a99a-1cb4c5d5a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_detailed_df.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
